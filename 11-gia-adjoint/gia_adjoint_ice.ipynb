{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346e6677",
   "metadata": {},
   "source": [
    "Synthetic ice inversion using adjoints\n",
    "=======================================================\n",
    "\n",
    "In this tutorial, we will use G-ADOPT's adjoint capability to invert for a synthetic ice\n",
    "load in an annulus domain. We will be running a 'twin' experiment where we will try to\n",
    "recover the ice load that we used as part of the earlier 2d cylindrical tutorial,\n",
    "starting from a different initial guess of the ice load.\n",
    "\n",
    "This example focusses on setting up an adjoint problem. These can be summarised as follows:\n",
    "1. Defining an objective function.\n",
    "2. Verifying the accuracy of the gradients using a Taylor test.\n",
    "3. Setting up and solving a gradient-based minimisation problem for a synthetic ice load."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb9a7b",
   "metadata": {},
   "source": [
    "This example\n",
    "-------------\n",
    "Let's get started!\n",
    "The first step is to import the gadopt module, which\n",
    "provides access to Firedrake and associated functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49132559",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from gadopt import *\n",
    "    from gadopt.utility import step_func, vertical_component, CombinedSurfaceMeasure\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    !wget \"https://fem-on-colab.github.io/releases/firedrake-install-real.sh\" -O \"/tmp/firedrake-install.sh\" && bash \"/tmp/firedrake-install.sh\"\n",
    "    !pip install gadopt[demos]\n",
    "    from gadopt import *\n",
    "    from gadopt.utility import step_func, vertical_component, CombinedSurfaceMeasure\n",
    "    import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf07fe90",
   "metadata": {},
   "source": [
    "To bring in G-ADOPT's adjoint functionality we need to start taping the forward problem,\n",
    "which we do below. It's also good practice to clear the tape, so that we are starting\n",
    "fresh each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gadopt.inverse import *\n",
    "tape = get_working_tape()\n",
    "tape.clear_tape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c365f7ee",
   "metadata": {},
   "source": [
    "In this tutorial we are going load the mesh created by the forward cylindrical demo in the\n",
    "previous tutorial. This makes it easier to load the synthetic data from the previous\n",
    "tutorial for our 'twin' experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b5668",
   "metadata": {},
   "source": [
    "Let's download a checkpoint file we made earlier. This is the same as the forward cylindrical demo except\n",
    "with a longer timestep of 1000 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f70fe",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "![ ! -f forward-2d-cylindrical-disp-incdisp-dt1ka.h5 ] && wget https://data.gadopt.org/demos/forward-2d-cylindrical-disp-incdisp-dt1ka.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up geometry:\n",
    "checkpoint_file = \"forward-2d-cylindrical-disp-incdisp-dt1ka.h5\"\n",
    "with CheckpointFile(checkpoint_file, 'r') as afile:\n",
    "    mesh = afile.load_mesh(name='surface_mesh_extruded')\n",
    "bottom_id, top_id = \"bottom\", \"top\"\n",
    "mesh.cartesian = False\n",
    "D = 2891e3  # Depth of domain in m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b052d29",
   "metadata": {},
   "source": [
    "We next set up the function spaces, and specify functions to hold our solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up function spaces - currently using the bilinear Q2Q1 element pair:\n",
    "V = VectorFunctionSpace(mesh, \"Q\", 2)  # (Incremental) Displacement function space (vector)\n",
    "W = FunctionSpace(mesh, \"Q\", 1)  # Pressure function space (scalar)\n",
    "S = TensorFunctionSpace(mesh, \"DQ\", 2)  # (Discontinuous) Stress tensor function space (tensor)\n",
    "R = FunctionSpace(mesh, \"R\", 0)  # Real function space (for constants)\n",
    "\n",
    "Z = MixedFunctionSpace([V, W])  # Mixed function space.\n",
    "\n",
    "z = Function(Z)  # A field over the mixed function space Z.\n",
    "u, p = split(z)  # Returns symbolic UFL expression for u and p\n",
    "z.subfunctions[0].rename(\"Incremental Displacement\")\n",
    "z.subfunctions[1].rename(\"Pressure\")\n",
    "\n",
    "displacement = Function(V, name=\"displacement\").assign(0)\n",
    "stress_old = Function(S, name=\"stress_old\").assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18936d1",
   "metadata": {},
   "source": [
    "Let's set up the background profiles for the material properties with the same values as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3851cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SpatialCoordinate(mesh)\n",
    "\n",
    "# layer properties from spada et al 2011\n",
    "radius_values = [6371e3, 6301e3, 5951e3, 5701e3, 3480e3]\n",
    "density_values = [3037, 3438, 3871, 4978]\n",
    "shear_modulus_values = [0.50605e11, 0.70363e11, 1.05490e11, 2.28340e11]\n",
    "viscosity_values = [2, -2, -2, -1.698970004]  # viscosity = 1e23 * 10**viscosity_values\n",
    "# N.b. that we have modified the viscosity of the Lithosphere viscosity from\n",
    "# Spada et al 2011 because we are using coarse grid resolution\n",
    "\n",
    "\n",
    "def initialise_background_field(field, background_values, vertical_tanh_width=40e3):\n",
    "    profile = background_values[0]\n",
    "    sharpness = 1 / vertical_tanh_width\n",
    "    depth = sqrt(X[0]**2 + X[1]**2)-radius_values[0]\n",
    "    for i in range(1, len(background_values)):\n",
    "        centre = radius_values[i] - radius_values[0]\n",
    "        mag = background_values[i] - background_values[i-1]\n",
    "        profile += step_func(depth, centre, mag, increasing=False, sharpness=sharpness)\n",
    "\n",
    "    field.interpolate(profile)\n",
    "\n",
    "\n",
    "density = Function(W, name=\"density\")\n",
    "initialise_background_field(density, density_values)\n",
    "\n",
    "shear_modulus = Function(W, name=\"shear modulus\")\n",
    "initialise_background_field(shear_modulus, shear_modulus_values)\n",
    "\n",
    "\n",
    "def bivariate_gaussian(x, y, mu_x, mu_y, sigma_x, sigma_y, rho, normalised_area=False):\n",
    "    arg = ((x-mu_x)/sigma_x)**2 - 2*rho*((x-mu_x)/sigma_x)*((y-mu_y)/sigma_y) + ((y-mu_y)/sigma_y)**2\n",
    "    numerator = exp(-1/(2*(1-rho**2))*arg)\n",
    "    if normalised_area:\n",
    "        denominator = 2*pi*sigma_x*sigma_y*(1-rho**2)**0.5\n",
    "    else:\n",
    "        denominator = 1\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def setup_heterogenous_viscosity(viscosity):\n",
    "    heterogenous_viscosity_field = Function(viscosity.function_space(), name='viscosity')\n",
    "    antarctica_x, antarctica_y = -2e6, -5.5e6\n",
    "\n",
    "    low_viscosity_antarctica = bivariate_gaussian(X[0], X[1], antarctica_x, antarctica_y, 1.5e6, 0.5e6, -0.4)\n",
    "    heterogenous_viscosity_field.interpolate(-3*low_viscosity_antarctica + viscosity * (1-low_viscosity_antarctica))\n",
    "\n",
    "    llsvp1_x, llsvp1_y = 3.5e6, 0\n",
    "    llsvp1 = bivariate_gaussian(X[0], X[1], llsvp1_x, llsvp1_y, 0.75e6, 1e6, 0)\n",
    "    heterogenous_viscosity_field.interpolate(-3*llsvp1 + heterogenous_viscosity_field * (1-llsvp1))\n",
    "\n",
    "    llsvp2_x, llsvp2_y = -3.5e6, 0\n",
    "    llsvp2 = bivariate_gaussian(X[0], X[1], llsvp2_x, llsvp2_y, 0.75e6, 1e6, 0)\n",
    "    heterogenous_viscosity_field.interpolate(-3*llsvp2 + heterogenous_viscosity_field * (1-llsvp2))\n",
    "\n",
    "    slab_x, slab_y = 3e6, 4.5e6\n",
    "    slab = bivariate_gaussian(X[0], X[1], slab_x, slab_y, 0.7e6, 0.35e6, 0.7)\n",
    "    heterogenous_viscosity_field.interpolate(-1*slab + heterogenous_viscosity_field * (1-slab))\n",
    "\n",
    "    high_viscosity_craton_x, high_viscosity_craton_y = 0, 6.2e6\n",
    "    high_viscosity_craton = bivariate_gaussian(X[0], X[1], high_viscosity_craton_x, high_viscosity_craton_y, 1.5e6, 0.5e6, 0.2)\n",
    "    heterogenous_viscosity_field.interpolate(-1*high_viscosity_craton + heterogenous_viscosity_field * (1-high_viscosity_craton))\n",
    "\n",
    "    return heterogenous_viscosity_field\n",
    "\n",
    "\n",
    "normalised_viscosity = Function(W, name=\"Normalised viscosity\")\n",
    "initialise_background_field(normalised_viscosity, viscosity_values)\n",
    "normalised_viscosity = setup_heterogenous_viscosity(normalised_viscosity)\n",
    "\n",
    "viscosity = Function(normalised_viscosity, name=\"viscosity\").interpolate(1e23*10**normalised_viscosity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b75ccf",
   "metadata": {},
   "source": [
    "Now let's setup the ice load. For this tutorial we will start with an ice thickness of zero\n",
    "everywhere, but our target ice load will be the same two synthetic ice sheets in the\n",
    "previous demo. An import step is to define our control, i.e. the thing that we are inverting\n",
    "for. In our case, this is the normalised ice thickness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d056b514",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "rho_ice = 931\n",
    "g = 9.8125\n",
    "\n",
    "Hice1 = 1000\n",
    "Hice2 = 2000\n",
    "year_in_seconds = Constant(3600 * 24 * 365.25)\n",
    "# Disc ice load but with a smooth transition given by a tanh profile\n",
    "disc_halfwidth1 = (2*pi/360) * 10  # Disk half width in radians\n",
    "disc_halfwidth2 = (2*pi/360) * 20  # Disk half width in radians\n",
    "surface_dx = 200*1e3\n",
    "ncells = 2*pi*radius_values[0] / surface_dx\n",
    "surface_resolution_radians = 2*pi / ncells\n",
    "colatitude = atan2(X[0], X[1])\n",
    "disc1_centre = (2*pi/360) * 25  # centre of disc1\n",
    "disc2_centre = pi  # centre of disc2\n",
    "disc1 = 0.5*(1-tanh((abs(colatitude-disc1_centre) - disc_halfwidth1) / (2*surface_resolution_radians)))\n",
    "disc2 = 0.5*(1-tanh((abs(abs(colatitude)-disc2_centre) - disc_halfwidth2) / (2*surface_resolution_radians)))\n",
    "\n",
    "target_normalised_ice_thickness = Function(W, name=\"target normalised ice thickness\")\n",
    "target_normalised_ice_thickness.interpolate(disc1 + (Hice2/Hice1)*disc2)\n",
    "\n",
    "normalised_ice_thickness = Function(W, name=\"normalised ice thickness\")\n",
    "\n",
    "control = Control(normalised_ice_thickness)\n",
    "ice_load = rho_ice * g * Hice1 * normalised_ice_thickness\n",
    "\n",
    "adj_ice_file = VTKFile(\"adj_ice.pvd\")\n",
    "# Since we are calculating the sensitivity to a field that is only defined\n",
    "# on the top boundary if we do the usual L2 projection (using the\n",
    "# mass matrix) to account for the size of the mesh element then we\n",
    "# will get spurious oscillating values in the output gradient in\n",
    "# cells not connected to the boundary. Instead we do the projection using\n",
    "# a surface integral, so that our output gradient accounts for the surface\n",
    "# area of each cell.\n",
    "converter = RieszL2BoundaryRepresentation(W, top_id)  # convert to surface L2 representation\n",
    "\n",
    "# We add a diagnostic block to the tape which will output the gradient\n",
    "# field every time the tape is replayed.\n",
    "tape.add_block(DiagnosticBlock(adj_ice_file, normalised_ice_thickness, riesz_options={'riesz_representation': converter}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9877bf34",
   "metadata": {},
   "source": [
    "Let's visualise the ice thickness using pyvista, by plotting a ring outside our synthetic Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8503fbf",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "pv.set_jupyter_backend(\"static\")\n",
    "pv.global_theme.notebook = True\n",
    "pv.start_xvfb()\n",
    "ice_cmap = plt.get_cmap(\"Blues\", 25)\n",
    "\n",
    "# Make two points at the bounds of the mesh and one at the center to\n",
    "# construct a circular arc.\n",
    "rmin = 3480e3\n",
    "rmax = 6371e3\n",
    "D = rmax-rmin\n",
    "nz = 32\n",
    "dz = D / nz\n",
    "\n",
    "normal = [0, 0, 1]\n",
    "polar = [radius_values[0]-dz/2, 0, 0]\n",
    "center = [0, 0, 0]\n",
    "angle = 360.0\n",
    "arc = pv.CircularArcFromNormal(center, 10000, normal, polar, angle)\n",
    "\n",
    "# Stretch line by 20%\n",
    "transform_matrix = np.array(\n",
    "    [\n",
    "        [1.2, 0, 0, 0],\n",
    "        [0, 1.2, 0, 0],\n",
    "        [0, 0, 1.2, 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ])\n",
    "\n",
    "\n",
    "def add_ice(p, m, scalar=\"normalised ice thickness\", scalar_bar_args=None):\n",
    "\n",
    "    if scalar_bar_args is None:\n",
    "        scalar_bar_args = {\n",
    "            \"title\": 'Normalised ice thickness',\n",
    "            \"position_x\": 0.2,\n",
    "            \"position_y\": 0.8,\n",
    "            \"vertical\": False,\n",
    "            \"title_font_size\": 22,\n",
    "            \"label_font_size\": 18,\n",
    "            \"fmt\": \"%.1f\",\n",
    "            \"font_family\": \"arial\",\n",
    "            \"n_labels\": 5,\n",
    "        }\n",
    "    data = m.read()[0]  # MultiBlock mesh with only 1 block\n",
    "\n",
    "    arc_data = arc.sample(data)\n",
    "\n",
    "    transformed_arc_data = arc_data.transform(transform_matrix)\n",
    "    p.add_mesh(transformed_arc_data, scalars=scalar, line_width=10, clim=[0, 2], cmap=ice_cmap, scalar_bar_args=scalar_bar_args)\n",
    "\n",
    "\n",
    "visc_file = VTKFile('viscosity.pvd').write(normalised_viscosity)\n",
    "reader = pv.get_reader(\"viscosity.pvd\")\n",
    "visc_data = reader.read()[0]  # MultiBlock mesh with only 1 block\n",
    "visc_cmap = plt.get_cmap(\"inferno_r\", 25)\n",
    "\n",
    "\n",
    "def add_viscosity(p):\n",
    "    p.add_mesh(\n",
    "        visc_data,\n",
    "        component=None,\n",
    "        lighting=False,\n",
    "        show_edges=False,\n",
    "        cmap=visc_cmap,\n",
    "        clim=[-3, 2],\n",
    "        scalar_bar_args={\n",
    "            \"title\": 'Normalised viscosity',\n",
    "            \"position_x\": 0.2,\n",
    "            \"position_y\": 0.1,\n",
    "            \"vertical\": False,\n",
    "            \"title_font_size\": 22,\n",
    "            \"label_font_size\": 18,\n",
    "            \"fmt\": \"%.0f\",\n",
    "            \"font_family\": \"arial\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Read the PVD file\n",
    "updated_ice_file = VTKFile('ice.pvd').write(normalised_ice_thickness, target_normalised_ice_thickness)\n",
    "reader = pv.get_reader(\"ice.pvd\")\n",
    "\n",
    "# Create a plotter object\n",
    "plotter = pv.Plotter(shape=(1, 2), border=False, notebook=True, off_screen=False)\n",
    "plotter.subplot(0, 0)\n",
    "add_ice(plotter, reader, 'target normalised ice thickness')\n",
    "add_viscosity(plotter)\n",
    "plotter.camera_position = 'xy'\n",
    "plotter.subplot(0, 1)\n",
    "add_ice(plotter, reader, 'normalised ice thickness')\n",
    "add_viscosity(plotter)\n",
    "\n",
    "plotter.camera_position = 'xy'\n",
    "plotter.show(jupyter_backend=\"static\", interactive=False)\n",
    "# Closes and finalizes movie\n",
    "plotter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7247ea",
   "metadata": {},
   "source": [
    "To make this simulation practical for a demo we are going to take longer timesteps than\n",
    "the previous 2d cylindrical demo. Let's choose a timestep (and output frequency) of 1000 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de052a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestepping parameters\n",
    "Tstart = 0\n",
    "time = Function(R).assign(Tstart * year_in_seconds)\n",
    "\n",
    "dt_years = 1000\n",
    "dt = Constant(dt_years * year_in_seconds)\n",
    "Tend_years = 10e3\n",
    "Tend = Constant(Tend_years * year_in_seconds)\n",
    "dt_out_years = 1e3\n",
    "dt_out = Constant(dt_out_years * year_in_seconds)\n",
    "\n",
    "max_timesteps = round((Tend - Tstart * year_in_seconds) / dt)\n",
    "log(\"max timesteps: \", max_timesteps)\n",
    "\n",
    "dump_period = round(dt_out / dt)\n",
    "log(\"dump_period:\", dump_period)\n",
    "log(f\"dt: {float(dt / year_in_seconds)} years\")\n",
    "log(f\"Simulation start time: {Tstart} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afca4d1",
   "metadata": {},
   "source": [
    "Similar to before, we setup the boundary conditions, this time using the normalised\n",
    "ice thickness to account for ice covered regions when calculating the density\n",
    "contrast across the free surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40a3c7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Setup boundary conditions\n",
    "exterior_density = rho_ice * normalised_ice_thickness\n",
    "stokes_bcs = {\n",
    "    top_id: {\n",
    "        'normal_stress': ice_load,\n",
    "        'free_surface': {'delta_rho_fs': density - exterior_density}\n",
    "    },\n",
    "    bottom_id: {'un': 0}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01dc1f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We also need to specify a G-ADOPT approximation, nullspaces and finally the\n",
    "stokes solver as before.  For this tutorial we will use a direct solver for\n",
    "the matrix system, so we don't need to provide the near nullspace like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "approximation = SmallDisplacementViscoelasticApproximation(density, shear_modulus, viscosity, g=g)\n",
    "\n",
    "Z_nullspace = create_stokes_nullspace(Z, closed=False, rotational=True)\n",
    "\n",
    "stokes_solver = ViscoelasticStokesSolver(z, stress_old, displacement, approximation,\n",
    "                                         dt, bcs=stokes_bcs, constant_jacobian=True,\n",
    "                                         nullspace=Z_nullspace, transpose_nullspace=Z_nullspace,\n",
    "                                         solver_parameters=\"direct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846923f",
   "metadata": {},
   "source": [
    "We next set up our output in VTK format. This format can be read by programs like pyvista and Paraview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38900ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a velocity function for plotting\n",
    "velocity = Function(V, name=\"velocity\")\n",
    "velocity.interpolate(z.subfunctions[0]/dt)\n",
    "# Create output file\n",
    "output_file = VTKFile(\"output.pvd\")\n",
    "output_file.write(*z.subfunctions, displacement, velocity)\n",
    "\n",
    "plog = ParameterLog(\"params.log\", mesh)\n",
    "plog.log_str(\n",
    "    \"timestep time dt u_rms u_rms_surf ux_max disp_min disp_max\"\n",
    ")\n",
    "\n",
    "checkpoint_filename = \"viscoelastic_loading-chk.h5\"\n",
    "\n",
    "gd = GeodynamicalDiagnostics(z, density, bottom_id, top_id)\n",
    "\n",
    "# Initialise a (scalar!) function for logging vertical displacement\n",
    "U = FunctionSpace(mesh, \"CG\", 2)  # (Incremental) Displacement function space (scalar)\n",
    "vertical_displacement = Function(U, name=\"Vertical displacement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb1b07",
   "metadata": {},
   "source": [
    "Now is a good time to setup a helper function for defining the time integrated misfit that we need\n",
    "later as part of our overall objective function. This is going to be called at each timestep of\n",
    "the forward run to calculate the difference between the displacement and velocity at the surface\n",
    "compared our reference forward simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6403b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_time_misfit(timestep, velocity_misfit, displacement_misfit):\n",
    "    with CheckpointFile(checkpoint_file, 'r') as afile:\n",
    "        target_incremental_displacement = afile.load_function(mesh, name=\"Incremental Displacement\", idx=timestep)\n",
    "        target_displacement = afile.load_function(mesh, name=\"Displacement\", idx=timestep)\n",
    "    circumference = 2 * pi * radius_values[0]\n",
    "    target_velocity = target_incremental_displacement/dt_years\n",
    "    velocity.interpolate(z.subfunctions[0]/dt_years)\n",
    "    velocity_error = velocity - target_velocity\n",
    "    velocity_scale = 10/dt_years\n",
    "    velocity_misfit += assemble(dot(velocity_error, velocity_error) / (circumference * velocity_scale**2) * ds(top_id))\n",
    "\n",
    "    displacement_error = displacement - target_displacement\n",
    "    displacement_scale = 50\n",
    "    displacement_misfit += assemble(dot(displacement_error, displacement_error) / (circumference * displacement_scale**2) * ds(top_id))\n",
    "    return velocity_misfit, displacement_misfit\n",
    "\n",
    "\n",
    "# Overload surface integral measure for G-ADOPT's extruded meshes.\n",
    "ds = CombinedSurfaceMeasure(mesh, degree=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb3549",
   "metadata": {},
   "source": [
    "Now let's run the simulation! This should be the same as before except we are calculating the surface\n",
    "misfit between our current simulation and the reference run at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a3891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_misfit = 0\n",
    "displacement_misfit = 0\n",
    "\n",
    "for timestep in range(max_timesteps+1):\n",
    "\n",
    "    stokes_solver.solve()\n",
    "    velocity_misfit, displacement_misfit = integrated_time_misfit(timestep, velocity_misfit, displacement_misfit)\n",
    "    time.assign(time+dt)\n",
    "\n",
    "    if timestep % dump_period == 0:\n",
    "        # First output step is after one solve i.e. roughly elastic displacement\n",
    "        # provided dt < maxwell time.\n",
    "        log(\"timestep\", timestep)\n",
    "\n",
    "        output_file.write(*z.subfunctions, displacement, velocity)\n",
    "\n",
    "        with CheckpointFile(checkpoint_filename, \"w\") as checkpoint:\n",
    "            checkpoint.save_function(z, name=\"Stokes\")\n",
    "            checkpoint.save_function(displacement, name=\"Displacement\")\n",
    "            checkpoint.save_function(stress_old, name=\"Deviatoric stress\")\n",
    "\n",
    "    vertical_displacement.interpolate(vertical_component(displacement))\n",
    "\n",
    "    # Log diagnostics:\n",
    "    plog.log_str(\n",
    "        f\"{timestep} {float(time)} {float(dt)} \"\n",
    "        f\"{gd.u_rms()} {gd.u_rms_top()} {gd.ux_max(top_id)} \"\n",
    "        f\"{vertical_displacement.dat.data.min()} {vertical_displacement.dat.data.max()}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918187e",
   "metadata": {},
   "source": [
    "As we can see from the plot below there is no displacement at the final time given there is no ice load!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef89647",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "# Read the PVD file\n",
    "reader = pv.get_reader(\"output.pvd\")\n",
    "data = reader.read()[0]  # MultiBlock mesh with only 1 block\n",
    "\n",
    "# Create a plotter object\n",
    "plotter = pv.Plotter(shape=(1, 1), border=False, notebook=True, off_screen=False)\n",
    "\n",
    "# Make a colour map\n",
    "boring_cmap = plt.get_cmap(\"inferno_r\", 25)\n",
    "\n",
    "# Read last timestep\n",
    "reader.set_active_time_point(10)\n",
    "data = reader.read()[0]\n",
    "# Artificially warp the output data in the vertical direction by the free surface height\n",
    "# Note the mesh is not really moving!\n",
    "warped = data.warp_by_vector(vectors=\"displacement\", factor=1500)\n",
    "arrows = warped.glyph(orient=\"velocity\", scale=\"velocity\", factor=1e14, tolerance=0.01)\n",
    "# Add the warped displacement field to the frame\n",
    "plotter.add_mesh(\n",
    "    warped,\n",
    "    scalars=\"displacement\",\n",
    "    component=None,\n",
    "    lighting=False,\n",
    "    clim=[0, 600],\n",
    "    cmap=boring_cmap,\n",
    "    scalar_bar_args={\n",
    "        \"title\": 'Displacement (m)',\n",
    "        \"position_x\": 0.85,\n",
    "        \"position_y\": 0.3,\n",
    "        \"vertical\": True,\n",
    "        \"title_font_size\": 20,\n",
    "        \"label_font_size\": 16,\n",
    "        \"fmt\": \"%.0f\",\n",
    "        \"font_family\": \"arial\",\n",
    "    }\n",
    ")\n",
    "\n",
    "ice_scalar_bar_args = {\"title\": 'Normalised ice thickness',\n",
    "                       \"position_x\": 0.1,\n",
    "                       \"position_y\": 0.3,\n",
    "                       \"vertical\": True,\n",
    "                       \"title_font_size\": 22,\n",
    "                       \"label_font_size\": 18,\n",
    "                       \"fmt\": \"%.1f\",\n",
    "                       \"font_family\": \"arial\",\n",
    "                       \"n_labels\": 5,\n",
    "                       }\n",
    "\n",
    "reader = pv.get_reader(\"ice.pvd\")\n",
    "add_ice(plotter, reader, 'normalised ice thickness', scalar_bar_args=ice_scalar_bar_args)\n",
    "plotter.camera_position = 'xy'\n",
    "plotter.show(jupyter_backend=\"static\", interactive=False)\n",
    "# Closes and finalizes movie\n",
    "plotter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a49b5",
   "metadata": {},
   "source": [
    "Now we can define our overall objective function that we want to minimise.\n",
    "This includes the time integrated displacement and velocity misfit at the\n",
    "surface as we discussed above. It is also a good idea to add a smoothing\n",
    "and damping term to help regularise the inversion problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0288ae2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "circumference = 2 * pi * radius_values[0]\n",
    "\n",
    "alpha_smoothing = 1\n",
    "alpha_damping = 0.1\n",
    "damping = assemble((normalised_ice_thickness) ** 2 / circumference * ds(top_id))\n",
    "smoothing = assemble(dot(grad(normalised_ice_thickness), grad(normalised_ice_thickness)) / circumference * ds(top_id))\n",
    "\n",
    "J = (displacement_misfit + velocity_misfit) / max_timesteps + alpha_damping * damping + alpha_smoothing * smoothing\n",
    "log(\"J = \", J)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7502c1",
   "metadata": {},
   "source": [
    "Let's also pause\n",
    "annotation as we are now done with the forward terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "pause_annotation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fe57bc",
   "metadata": {},
   "source": [
    "Let's setup some call backs to help us keep track of the inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_ice_thickness = Function(normalised_ice_thickness, name=\"updated ice thickness\")\n",
    "updated_ice_thickness_file = VTKFile(\"updated_ice_thickness.pvd\")\n",
    "updated_displacement = Function(displacement, name=\"updated displacement\")\n",
    "updated_velocity = Function(z.subfunctions[0], name=\"updated velocity\")\n",
    "updated_out_file = VTKFile(\"updated_out.pvd\")\n",
    "\n",
    "with CheckpointFile(checkpoint_file, 'r') as afile:\n",
    "    final_target_incremental_displacement = afile.load_function(mesh, name=\"Incremental Displacement\", idx=10)\n",
    "    final_target_displacement = afile.load_function(mesh, name=\"Displacement\", idx=10)\n",
    "\n",
    "final_target_velocity = Function(V, name=\"target velocity\").interpolate(final_target_incremental_displacement / dt_years)\n",
    "functional_values = []\n",
    "\n",
    "\n",
    "def eval_cb(J, m):\n",
    "    if functional_values:\n",
    "        functional_values.append(min(J, min(functional_values)))\n",
    "    else:\n",
    "        functional_values.append(J)\n",
    "\n",
    "    circumference = 2 * pi * radius_values[0]\n",
    "    # Define the component terms of the overall objective functional\n",
    "    log(\"displacement misfit\", displacement_misfit.block_variable.checkpoint / max_timesteps)\n",
    "    log(\"velocity misfit\", velocity_misfit.block_variable.checkpoint / max_timesteps)\n",
    "\n",
    "    damping = alpha_damping * assemble((normalised_ice_thickness.block_variable.checkpoint) ** 2 / circumference * ds(top_id))\n",
    "    smoothing = alpha_smoothing * assemble(dot(grad(normalised_ice_thickness.block_variable.checkpoint), grad(normalised_ice_thickness.block_variable.checkpoint)) / circumference * ds(top_id))\n",
    "    log(\"damping\", damping)\n",
    "    log(\"smoothing\", smoothing)\n",
    "\n",
    "    # Write out values of control and final forward model results\n",
    "    updated_ice_thickness.assign(m)\n",
    "    updated_ice_thickness_file.write(updated_ice_thickness, target_normalised_ice_thickness)\n",
    "    updated_displacement.interpolate(displacement.block_variable.checkpoint)\n",
    "    updated_velocity.interpolate(z.subfunctions[0].block_variable.checkpoint / dt)\n",
    "    updated_out_file.write(updated_displacement, final_target_displacement, updated_velocity, final_target_velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9eab5",
   "metadata": {},
   "source": [
    "The next important step is to define the reduced functional. This is pyadjoint's way of\n",
    "associating our objective function with the control variable that we are trying to\n",
    "optimise. We can pass our call back function which will be called every time\n",
    "the functional is evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aae7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_functional = ReducedFunctional(J, control, eval_cb_post=eval_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d34ad",
   "metadata": {},
   "source": [
    "A good check to see if the forward taping worked is to rerun the forward model based on\n",
    "the operations stored on the tape. We can do this by providing the control to the\n",
    "reducted functional and print out the answer - it is good to see they are the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ccdbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"J\", J)\n",
    "log(\"replay tape RF\", reduced_functional(normalised_ice_thickness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2186f32",
   "metadata": {},
   "source": [
    "We can now calculate the derivative of our objective function with respect to the\n",
    "ice thickness.  This is as simple as calling the `derivative()` method on  our\n",
    "reduced functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ecb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dJdm = reduced_functional.derivative()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94219a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "We can also plot the derivative using pyvista. First of all let's define another helper\n",
    "function to plot the sensitivity to the ice thickness as a ring outside the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sensitivity_ring(p, m, scalar_bar_args=None):\n",
    "    # Make a colour map\n",
    "    adj_cmap = plt.get_cmap(\"coolwarm\", 25)\n",
    "    if scalar_bar_args is None:\n",
    "        scalar_bar_args = {\n",
    "            \"title\": 'Adjoint sensitivity',\n",
    "            \"position_x\": 0.2,\n",
    "            \"position_y\": 0.8,\n",
    "            \"vertical\": False,\n",
    "            \"title_font_size\": 22,\n",
    "            \"label_font_size\": 18,\n",
    "            \"fmt\": \"%.1e\",\n",
    "            \"font_family\": \"arial\",\n",
    "            \"n_labels\": 3,\n",
    "        }\n",
    "    data = m.read()[0]  # MultiBlock mesh with only 1 block\n",
    "\n",
    "    arc_data = arc.sample(data)\n",
    "\n",
    "    transform_matrix = np.array(\n",
    "        [\n",
    "            [1.1, 0, 0, 0],\n",
    "            [0, 1.1, 0, 0],\n",
    "            [0, 0, 1.1, 0],\n",
    "            [0, 0, 0, 1],\n",
    "        ])\n",
    "\n",
    "    transformed_arc_data = arc_data.transform(transform_matrix)\n",
    "    p.add_mesh(transformed_arc_data, line_width=8, scalar_bar_args=scalar_bar_args, clim=[-5e-7, 5e-7], cmap=adj_cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de359b7",
   "metadata": {},
   "source": [
    "Next we read in the file that was written out as part of the diagnostic callback\n",
    "added to the tape earlier. We can see there is a clear hemispherical pattern in\n",
    "the gradients. Red indicates that increasing the ice thickness here would increase\n",
    "out objective function and blue areas indicates that increasing the ice thickness\n",
    "here would decrease our objective function. In the 'southern' hemisphere\n",
    "where we have the biggest ice load the gradient is negative, which makes sense as\n",
    "we expect increasing the ice thickness here to reduce our surface misfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b192ff54",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "# Read the PVD file\n",
    "reader = pv.get_reader(\"ice.pvd\")\n",
    "adj_reader = pv.get_reader(\"adj_ice.pvd\")\n",
    "# Create a plotter object\n",
    "plotter = pv.Plotter(shape=(1, 2), border=False, notebook=True, off_screen=False)\n",
    "plotter.subplot(0, 0)\n",
    "add_ice(plotter, reader, 'target normalised ice thickness')\n",
    "add_viscosity(plotter)\n",
    "plotter.camera_position = 'xy'\n",
    "plotter.subplot(0, 1)\n",
    "add_ice(plotter, reader, 'normalised ice thickness')\n",
    "add_viscosity(plotter)\n",
    "\n",
    "add_sensitivity_ring(plotter, adj_reader)\n",
    "plotter.camera_position = 'xy'\n",
    "plotter.show(jupyter_backend=\"static\", interactive=False)\n",
    "# Closes and finalizes movie\n",
    "plotter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406283a",
   "metadata": {},
   "source": [
    "A good way to verify this the gradient is correct is to carry out a Taylor test. For the control, $I_h$,\n",
    "reduced functional, $J(I_h)$, and its derivative,\n",
    "$\\frac{\\mathrm{d} J}{\\mathrm{d} I_h}$, the Taylor remainder convergence test can be expressed as:\n",
    "\n",
    "$$ \\left| J(I_h + h \\,\\delta I_h) - J(I_h) - h\\,\\frac{\\mathrm{d} J}{\\mathrm{d} I_h} \\cdot \\delta I_h \\right| \\longrightarrow 0 \\text{ at } O(h^2). $$\n",
    "\n",
    "The expression on the left-hand side is termed the second-order Taylor remainder. i\n",
    "This term's convergence rate of $O(h^2)$ is a robust indicator for\n",
    "verifying the computational implementation of the gradient calculation.\n",
    "Essentially, if you halve the value of $h$, the magnitude\n",
    "of the second-order Taylor remainder should decrease by a factor of 4.\n",
    "\n",
    "We employ these so-called *Taylor tests* to confirm the accuracy of the\n",
    "determined gradients. The theoretical convergence rate is\n",
    "$O(2.0)$, and achieving this rate indicates that the gradient information\n",
    "is accurate down to floating-point precision.\n",
    "\n",
    "### Performing Taylor Tests\n",
    "\n",
    "In our implementation, we perform a second-order Taylor remainder test for each\n",
    "term of the objective functional. The test involves\n",
    "computing the functional and the associated gradient when randomly perturbing\n",
    "the initial temperature field, $T_{ic}$, and subsequently\n",
    "halving the perturbations at each level.\n",
    "\n",
    "Here is how you can perform a Taylor test in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa868c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Function(normalised_ice_thickness)\n",
    "h.dat.data[:] = np.random.random(h.dat.data_ro.shape)\n",
    "taylor_test(reduced_functional, normalised_ice_thickness, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f440f46b",
   "metadata": {},
   "source": [
    "Now that we have verified our gradient is correct, let's start setting up an inversion.\n",
    "First of all we will define some bounds that we enforce the control to lie within.\n",
    "For this problem the lower bound of zero ice thickness is particularly important,\n",
    "as we do not want negative ice thicknesses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd4a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_thickness_lb = Function(normalised_ice_thickness.function_space(), name=\"Lower bound ice thickness\")\n",
    "ice_thickness_ub = Function(normalised_ice_thickness.function_space(), name=\"Upper bound ice thickness\")\n",
    "ice_thickness_lb.assign(0.0)\n",
    "ice_thickness_ub.assign(5)\n",
    "\n",
    "bounds = [ice_thickness_lb, ice_thickness_ub]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f878a0",
   "metadata": {},
   "source": [
    "Next we setup a pyadjoint minimization problem. We tweak GADOPT's default minimisation\n",
    "parameters (found in `gadopt/inverse.py`) for our problem. We limit the number of\n",
    "iterations to 15 just so that the demo is quick to run. We also increase the size of\n",
    "the initial radius of the trust region so that the inversion gets going a bit quicker\n",
    "than the default setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83b90c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "minimisation_problem = MinimizationProblem(reduced_functional, bounds=bounds)\n",
    "\n",
    "minimisation_parameters[\"Status Test\"][\"Iteration Limit\"] = 15\n",
    "minimisation_parameters[\"Step\"][\"Trust Region\"][\"Initial Radius\"] = 1e4\n",
    "\n",
    "optimiser = LinMoreOptimiser(\n",
    "    minimisation_problem,\n",
    "    minimisation_parameters,\n",
    "    checkpoint_dir=\"optimisation_checkpoint\",\n",
    ")\n",
    "# Restart file for optimisation...\n",
    "updated_ice_thickness_file = VTKFile(\"updated_ice_thickness.pvd\")\n",
    "updated_out_file = VTKFile(\"updated_out.pvd\")\n",
    "functional_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07daecc1",
   "metadata": {},
   "source": [
    "Now let's run the inversion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3dc940",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b98cb9",
   "metadata": {},
   "source": [
    "If we're performing mulitple successive optimisations, we want\n",
    "to ensure the annotations are switched back on for the next code\n",
    "to use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d814a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_annotation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818fca21",
   "metadata": {},
   "source": [
    "Let's plot the results of the inversion at the final iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ae1ba",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "# Read the PVD file\n",
    "reader = pv.get_reader(\"updated_out.pvd\")\n",
    "data = reader.read()[0]  # MultiBlock mesh with only 1 block\n",
    "\n",
    "# Create a plotter object\n",
    "plotter = pv.Plotter(shape=(1, 1), border=False, notebook=True, off_screen=False)\n",
    "\n",
    "# Make a colour map\n",
    "boring_cmap = plt.get_cmap(\"inferno_r\", 25)\n",
    "\n",
    "# Read last timestep\n",
    "reader.set_active_time_point(15)\n",
    "data = reader.read()[0]\n",
    "# Artificially warp the output data by the displacement field\n",
    "# Note the mesh is not really moving!\n",
    "warped = data.warp_by_vector(vectors=\"updated displacement\", factor=1500)\n",
    "arrows = warped.glyph(orient=\"updated velocity\", scale=\"updated velocity\", factor=1e14, tolerance=0.01)\n",
    "# Add the warped displacement field to the frame\n",
    "plotter.add_mesh(\n",
    "    warped,\n",
    "    scalars=\"updated displacement\",\n",
    "    component=None,\n",
    "    lighting=False,\n",
    "    clim=[0, 600],\n",
    "    cmap=boring_cmap,\n",
    "    scalar_bar_args={\n",
    "        \"title\": 'Displacement (m)',\n",
    "        \"position_x\": 0.85,\n",
    "        \"position_y\": 0.3,\n",
    "        \"vertical\": True,\n",
    "        \"title_font_size\": 20,\n",
    "        \"label_font_size\": 16,\n",
    "        \"fmt\": \"%.0f\",\n",
    "        \"font_family\": \"arial\",\n",
    "    }\n",
    ")\n",
    "\n",
    "ice_scalar_bar_args = {\"title\": 'Normalised ice thickness',\n",
    "                       \"position_x\": 0.1,\n",
    "                       \"position_y\": 0.3,\n",
    "                       \"vertical\": True,\n",
    "                       \"title_font_size\": 22,\n",
    "                       \"label_font_size\": 18,\n",
    "                       \"fmt\": \"%.1f\",\n",
    "                       \"font_family\": \"arial\",\n",
    "                       \"n_labels\": 5,\n",
    "                       }\n",
    "\n",
    "reader = pv.get_reader(\"updated_ice_thickness.pvd\")\n",
    "reader.set_active_time_point(15)\n",
    "add_ice(plotter, reader, 'updated ice thickness', scalar_bar_args=ice_scalar_bar_args)\n",
    "\n",
    "adj_scalar_bar_args = {\n",
    "            \"title\": 'Adjoint sensitivity',\n",
    "            \"position_x\": 0.2,\n",
    "            \"position_y\": 0.05,\n",
    "            \"vertical\": False,\n",
    "            \"title_font_size\": 22,\n",
    "            \"label_font_size\": 18,\n",
    "            \"fmt\": \"%.1e\",\n",
    "            \"font_family\": \"arial\",\n",
    "            \"n_labels\": 3,\n",
    "        }\n",
    "\n",
    "adj_reader = pv.get_reader(\"adj_ice.pvd\")\n",
    "adj_reader.set_active_time_point(15)\n",
    "add_sensitivity_ring(plotter, adj_reader, scalar_bar_args=adj_scalar_bar_args)\n",
    "plotter.camera_position = 'xy'\n",
    "plotter.show(jupyter_backend=\"static\", interactive=False)\n",
    "# Closes and finalizes movie\n",
    "plotter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974564ed",
   "metadata": {},
   "source": [
    "We can see that we have been able to recover two ice sheets in the correct locations and\n",
    "the final displacement pattern is very similar to the target run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5970a6a",
   "metadata": {},
   "source": [
    "And we'll write the functional values to a file so that we can test them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8892ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"functional_field.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(str(x) for x in functional_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09bdb4",
   "metadata": {},
   "source": [
    "We can confirm that\n",
    "the surface misfit has reduced by plotting the objective function at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457c270",
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "plt.semilogy(functional_values)\n",
    "plt.xlabel(\"Iteration #\")\n",
    "plt.ylabel(\"Functional value\")\n",
    "plt.title(\"Convergence\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
